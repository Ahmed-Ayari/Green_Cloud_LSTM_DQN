{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2725af20",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bcdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from ml_models.data_preprocessing import WorkloadDataLoader\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Imports completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582d1cc",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Load Workload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = WorkloadDataLoader()\n",
    "\n",
    "# Generate synthetic workload for demonstration\n",
    "# Replace with real data: data_loader.load_planetlab_trace('../data/planetlab/trace.txt')\n",
    "workload_data = data_loader.generate_synthetic_workload(\n",
    "    num_hosts=10,\n",
    "    num_timesteps=1000,\n",
    "    pattern='mixed'\n",
    ")\n",
    "\n",
    "print(f\"Loaded workload data: {workload_data.shape}\")\n",
    "print(f\"Hosts: {workload_data.shape[1]}, Timesteps: {workload_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd5f64",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(\n",
    "    workload_data,\n",
    "    columns=[f'Host_{i}' for i in range(workload_data.shape[1])]\n",
    ")\n",
    "df['Timestamp'] = pd.date_range(start='2024-01-01', periods=len(df), freq='5min')\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nðŸ“Š Summary Statistics (CPU Utilization %):\\n\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770fd54",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Workload Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a248c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribution of utilization values\n",
    "axes[0, 0].hist(df.values.flatten(), bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('CPU Utilization Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Utilization (%)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df.values.flatten().mean(), color='red', linestyle='--', label=f'Mean: {df.values.flatten().mean():.2f}%')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Box plot per host\n",
    "df.boxplot(ax=axes[0, 1])\n",
    "axes[0, 1].set_title('CPU Utilization by Host', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Utilization (%)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Time series plot (first 3 hosts)\n",
    "df.iloc[:, :3].plot(ax=axes[1, 0], linewidth=1.5)\n",
    "axes[1, 0].set_title('CPU Utilization Over Time (Sample Hosts)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Utilization (%)')\n",
    "axes[1, 0].legend(loc='upper right')\n",
    "\n",
    "# 4. Correlation heatmap\n",
    "correlation = df.corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', ax=axes[1, 1], cbar_kws={'label': 'Correlation'})\n",
    "axes[1, 1].set_title('Host Utilization Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/data_exploration.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Workload distribution analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cb1c6",
   "metadata": {},
   "source": [
    "## ðŸ•’ Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# 1. Hourly average utilization\n",
    "df['Hour'] = df.index.hour\n",
    "hourly_avg = df.groupby('Hour').mean().mean(axis=1)\n",
    "axes[0].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2, markersize=8, color='teal')\n",
    "axes[0].set_title('Average CPU Utilization by Hour of Day', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Hour')\n",
    "axes[0].set_ylabel('Avg Utilization (%)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(range(24))\n",
    "\n",
    "# 2. Rolling average (window=50)\n",
    "rolling_avg = df.iloc[:, :3].rolling(window=50).mean()\n",
    "rolling_avg.plot(ax=axes[1], linewidth=2)\n",
    "axes[1].set_title('CPU Utilization - Rolling Average (Window=50)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Utilization (%)')\n",
    "axes[1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/temporal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Temporal pattern analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230fa41f",
   "metadata": {},
   "source": [
    "## ðŸŽ² Synthetic Workload Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd639a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different workload patterns\n",
    "patterns = ['sine', 'random', 'spike', 'mixed']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, pattern in enumerate(patterns):\n",
    "    synthetic_data = data_loader.generate_synthetic_workload(\n",
    "        num_hosts=3,\n",
    "        num_timesteps=500,\n",
    "        pattern=pattern\n",
    "    )\n",
    "    \n",
    "    # Plot each host\n",
    "    for host_idx in range(3):\n",
    "        axes[i].plot(synthetic_data[:, host_idx], label=f'Host {host_idx}', linewidth=1.5)\n",
    "    \n",
    "    axes[i].set_title(f'Pattern: {pattern.upper()}', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Timestep')\n",
    "    axes[i].set_ylabel('Utilization (%)')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/synthetic_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Synthetic workload generation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a9969c",
   "metadata": {},
   "source": [
    "## ðŸ“Š Host-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate VM-to-Host mapping\n",
    "num_vms = 50\n",
    "vm_data = data_loader.generate_synthetic_workload(\n",
    "    num_hosts=num_vms,\n",
    "    num_timesteps=500,\n",
    "    pattern='mixed'\n",
    ")\n",
    "\n",
    "# Random VM-to-Host assignment\n",
    "np.random.seed(42)\n",
    "vm_to_host = {f'VM_{i}': f'Host_{np.random.randint(0, 10)}' for i in range(num_vms)}\n",
    "\n",
    "# Aggregate to host level\n",
    "host_data = data_loader.aggregate_to_host_level(vm_data, vm_to_host)\n",
    "\n",
    "print(f\"VM data shape: {vm_data.shape}\")\n",
    "print(f\"Host aggregated data shape: {host_data.shape}\")\n",
    "print(f\"\\nHost utilization summary (%):\\n{pd.DataFrame(host_data).describe()}\")\n",
    "\n",
    "# Visualize aggregation\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "pd.DataFrame(host_data, columns=[f'Host_{i}' for i in range(host_data.shape[1])]).plot(ax=ax, linewidth=2)\n",
    "ax.set_title('Aggregated Host CPU Utilization', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Timestep')\n",
    "ax.set_ylabel('Utilization (%)')\n",
    "ax.legend(loc='upper right', ncol=5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/host_aggregation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Host-level aggregation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f408e8",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Export Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save workload data\n",
    "np.save('../data/processed/workload_data.npy', workload_data)\n",
    "np.save('../data/processed/host_aggregated_data.npy', host_data)\n",
    "\n",
    "# Save DataFrame as CSV\n",
    "df.to_csv('../data/processed/workload_timeseries.csv')\n",
    "\n",
    "print(\"âœ… Data exported successfully!\")\n",
    "print(\"   - workload_data.npy\")\n",
    "print(\"   - host_aggregated_data.npy\")\n",
    "print(\"   - workload_timeseries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0af3a1",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Summary\n",
    "\n",
    "**Key Findings:**\n",
    "- âœ… Workload data loaded and preprocessed successfully\n",
    "- âœ… Temporal patterns identified (hourly variations)\n",
    "- âœ… Synthetic workload generators validated\n",
    "- âœ… Host-level aggregation implemented\n",
    "- âœ… Data exported for model training\n",
    "\n",
    "**Next Steps:**\n",
    "1. Train LSTM workload predictors (see `02_lstm_analysis.ipynb`)\n",
    "2. Train DQN consolidation agent (see `03_dqn_training.ipynb`)\n",
    "3. Evaluate and visualize results (see `04_results_visualization.ipynb`)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

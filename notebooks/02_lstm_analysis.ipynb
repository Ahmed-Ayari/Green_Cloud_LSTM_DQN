{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b764d240",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from ml_models.lstm_predictor import LSTMPredictor, MultiResourceLSTM\n",
    "from ml_models.data_preprocessing import WorkloadDataLoader\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Imports completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bdf2d",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data_loader = WorkloadDataLoader()\n",
    "workload_data = data_loader.generate_synthetic_workload(\n",
    "    num_hosts=10,\n",
    "    num_timesteps=1000,\n",
    "    pattern='mixed'\n",
    ")\n",
    "\n",
    "# Select one host for detailed analysis\n",
    "host_0_data = workload_data[:, 0]\n",
    "\n",
    "# Train/test split\n",
    "train_size = int(0.8 * len(host_0_data))\n",
    "train_data = host_0_data[:train_size]\n",
    "test_data = host_0_data[train_size:]\n",
    "\n",
    "print(f\"Total data points: {len(host_0_data)}\")\n",
    "print(f\"Training data: {len(train_data)} points\")\n",
    "print(f\"Test data: {len(test_data)} points\")\n",
    "\n",
    "# Visualize train/test split\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(range(len(train_data)), train_data, label='Training Data', color='blue', alpha=0.7)\n",
    "plt.plot(range(len(train_data), len(host_0_data)), test_data, label='Test Data', color='orange', alpha=0.7)\n",
    "plt.axvline(train_size, color='red', linestyle='--', label='Train/Test Split')\n",
    "plt.title('Host 0 CPU Utilization - Train/Test Split', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Utilization (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba538cd",
   "metadata": {},
   "source": [
    "## ðŸ‹ï¸ Train LSTM Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM predictor\n",
    "lstm_predictor = LSTMPredictor(\n",
    "    sequence_length=10,\n",
    "    lstm_units=64,\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training LSTM model...\")\n",
    "history = lstm_predictor.train(\n",
    "    data=train_data,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26283f",
   "metadata": {},
   "source": [
    "## ðŸ“Š Training Progress Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab96901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Model Loss During Training', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE curve\n",
    "axes[1].plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_title('Mean Absolute Error During Training', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/lstm_training_progress.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0c8fe",
   "metadata": {},
   "source": [
    "## ðŸ”® Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ba934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = []\n",
    "actual_values = []\n",
    "\n",
    "# Use sliding window over test data\n",
    "for i in range(lstm_predictor.sequence_length, len(test_data)):\n",
    "    sequence = test_data[i - lstm_predictor.sequence_length:i]\n",
    "    pred = lstm_predictor.predict(sequence)\n",
    "    predictions.append(pred[0])\n",
    "    actual_values.append(test_data[i])\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "actual_values = np.array(actual_values)\n",
    "\n",
    "print(f\"Generated {len(predictions)} predictions on test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d3189",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Prediction Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse = mean_squared_error(actual_values, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actual_values, predictions)\n",
    "r2 = r2_score(actual_values, predictions)\n",
    "mape = np.mean(np.abs((actual_values - predictions) / actual_values)) * 100\n",
    "\n",
    "print(\"\\nðŸ“Š Prediction Accuracy Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean Squared Error (MSE):     {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE):    {mae:.4f}\")\n",
    "print(f\"RÂ² Score:                     {r2:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a76366",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Prediction vs Actual Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# 1. Time series comparison\n",
    "timesteps = range(len(predictions))\n",
    "axes[0].plot(timesteps, actual_values, label='Actual', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(timesteps, predictions, label='Predicted', linewidth=2, alpha=0.7, linestyle='--')\n",
    "axes[0].set_title('LSTM Predictions vs Actual Values', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Timestep')\n",
    "axes[0].set_ylabel('CPU Utilization (%)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Scatter plot\n",
    "axes[1].scatter(actual_values, predictions, alpha=0.5, s=30)\n",
    "axes[1].plot([actual_values.min(), actual_values.max()], \n",
    "             [actual_values.min(), actual_values.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_title('Actual vs Predicted - Scatter Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Actual Utilization (%)')\n",
    "axes[1].set_ylabel('Predicted Utilization (%)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add RÂ² annotation\n",
    "axes[1].text(0.05, 0.95, f'RÂ² = {r2:.4f}', \n",
    "             transform=axes[1].transAxes, \n",
    "             fontsize=12, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/lstm_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e16969",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Prediction Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction errors\n",
    "errors = actual_values - predictions\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# 1. Error distribution\n",
    "axes[0].hist(errors, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "axes[0].axvline(errors.mean(), color='blue', linestyle='--', linewidth=2, label=f'Mean Error: {errors.mean():.2f}')\n",
    "axes[0].set_title('Prediction Error Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Error (Actual - Predicted)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error over time\n",
    "axes[1].plot(timesteps, errors, color='red', alpha=0.6)\n",
    "axes[1].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1].fill_between(timesteps, 0, errors, where=(errors > 0), color='red', alpha=0.3, label='Underestimation')\n",
    "axes[1].fill_between(timesteps, 0, errors, where=(errors < 0), color='green', alpha=0.3, label='Overestimation')\n",
    "axes[1].set_title('Prediction Error Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Timestep')\n",
    "axes[1].set_ylabel('Error')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/lstm_error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError Statistics:\")\n",
    "print(f\"Mean Error: {errors.mean():.4f}\")\n",
    "print(f\"Std Dev: {errors.std():.4f}\")\n",
    "print(f\"Min Error: {errors.min():.4f}\")\n",
    "print(f\"Max Error: {errors.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff6f1d",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Trend Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trend detection\n",
    "trend_predictions = []\n",
    "\n",
    "for i in range(lstm_predictor.sequence_length, len(test_data)):\n",
    "    sequence = test_data[i - lstm_predictor.sequence_length:i]\n",
    "    trend = lstm_predictor.predict_trend(sequence)\n",
    "    trend_predictions.append(trend)\n",
    "\n",
    "# Count trend occurrences\n",
    "from collections import Counter\n",
    "trend_counts = Counter(trend_predictions)\n",
    "\n",
    "print(\"\\nðŸ“Š Trend Detection Results:\")\n",
    "print(\"=\" * 50)\n",
    "for trend, count in trend_counts.items():\n",
    "    percentage = (count / len(trend_predictions)) * 100\n",
    "    print(f\"{trend.upper()}: {count} ({percentage:.2f}%)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Visualize trend distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Pie chart\n",
    "colors = {'increasing': '#ff9999', 'stable': '#66b3ff', 'decreasing': '#99ff99'}\n",
    "trend_colors = [colors[trend] for trend in trend_counts.keys()]\n",
    "axes[0].pie(trend_counts.values(), labels=trend_counts.keys(), autopct='%1.1f%%', \n",
    "            colors=trend_colors, startangle=90)\n",
    "axes[0].set_title('Workload Trend Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Trend over time\n",
    "trend_map = {'increasing': 1, 'stable': 0, 'decreasing': -1}\n",
    "trend_numeric = [trend_map[t] for t in trend_predictions]\n",
    "axes[1].plot(trend_numeric, linewidth=1, color='purple')\n",
    "axes[1].set_title('Detected Trends Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Timestep')\n",
    "axes[1].set_ylabel('Trend (-1: Decreasing, 0: Stable, 1: Increasing)')\n",
    "axes[1].set_yticks([-1, 0, 1])\n",
    "axes[1].set_yticklabels(['Decreasing', 'Stable', 'Increasing'])\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/graphs/lstm_trend_detection.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3eb40",
   "metadata": {},
   "source": [
    "## ðŸ” Multi-Resource LSTM (CPU + RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76769fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-resource data\n",
    "cpu_data = workload_data[:, 0]\n",
    "ram_data = workload_data[:, 1]\n",
    "\n",
    "# Train multi-resource predictor\n",
    "multi_predictor = MultiResourceLSTM(\n",
    "    sequence_length=10,\n",
    "    lstm_units=64,\n",
    "    num_resources=2\n",
    ")\n",
    "\n",
    "print(\"Training Multi-Resource LSTM...\")\n",
    "multi_history = multi_predictor.train(\n",
    "    cpu_data=cpu_data[:train_size],\n",
    "    ram_data=ram_data[:train_size],\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Multi-Resource LSTM training completed!\")\n",
    "\n",
    "# Make predictions\n",
    "cpu_pred, ram_pred = multi_predictor.predict(\n",
    "    cpu_data[train_size-10:train_size],\n",
    "    ram_data[train_size-10:train_size]\n",
    ")\n",
    "\n",
    "print(f\"\\nPredicted CPU Utilization: {cpu_pred[0]:.2f}%\")\n",
    "print(f\"Predicted RAM Utilization: {ram_pred[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b521d219",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c56c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "lstm_predictor.save('../models/lstm_predictor_host0.h5')\n",
    "multi_predictor.save('../models/multi_resource_lstm.h5')\n",
    "\n",
    "print(\"âœ… Models saved successfully!\")\n",
    "print(\"   - lstm_predictor_host0.h5\")\n",
    "print(\"   - multi_resource_lstm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6b9a5",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Summary\n",
    "\n",
    "**Key Results:**\n",
    "- âœ… LSTM model trained successfully with low validation loss\n",
    "- âœ… Prediction accuracy: RÂ² = {r2:.4f}, MAE = {mae:.4f}\n",
    "- âœ… Trend detection identifies workload patterns effectively\n",
    "- âœ… Multi-resource prediction supports CPU + RAM forecasting\n",
    "- âœ… Models saved for integration with DQN agent\n",
    "\n",
    "**Next Steps:**\n",
    "1. Integrate LSTM predictions with DQN agent (see `03_dqn_training.ipynb`)\n",
    "2. Evaluate full LSTM-DQN hybrid system\n",
    "3. Compare with baseline algorithms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
